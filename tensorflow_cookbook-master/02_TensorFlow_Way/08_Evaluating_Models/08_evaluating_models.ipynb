{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models\n",
    "\n",
    "This code will implement two models.  The first is a simple regression model, we will show how to call the loss function, MSE during training, and output it after for test and training sets.\n",
    "\n",
    "The second model will be a simple classification model.  We will also show how to print percent classified for both the test and training sets.\n",
    "\n",
    "### Regression Model\n",
    "\n",
    "For the regression model we will generate 100 random samples from a Normal(mean=1, sd=0.1).  The target will be an array of size 100 filled with the target value of 10.0.\n",
    "\n",
    "We will fit the linear model $y=A \\cdot x$ (no y intercept).  The theoretical value of `A` is `10.0`.\n",
    "\n",
    "To start we load the necessary libraries and reset the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a graph session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for Regression\n",
    "\n",
    "Here we generate the data required for the regression.  We also specify the necessary placeholders.\n",
    "\n",
    "After we split the data into a 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the model variable `A` and the multiplication operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Add operation to graph\n",
    "my_output = tf.matmul(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimization Function, and Variable Initialization\n",
    "\n",
    "We use the L2 loss, and the standard Gradient Descent Optimization with a learning rate of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add L2 loss operation to graph\n",
    "loss = tf.reduce_mean(tf.square(my_output - y_target))\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regression\n",
    "\n",
    "We iterate 100 times through the training step, selecting a random batch of data each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25 A = [[ 6.47693586]]\n",
      "Loss = 12.0633\n",
      "Step #50 A = [[ 8.68510914]]\n",
      "Loss = 2.556\n",
      "Step #75 A = [[ 9.50503254]]\n",
      "Loss = 1.21711\n",
      "Step #100 A = [[ 9.77385426]]\n",
      "Loss = 1.04426\n"
     ]
    }
   ],
   "source": [
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = np.transpose([x_vals_train[rand_index]])\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%25==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Regression Model\n",
    "\n",
    "For the regression model evaluation, we will run the loss wih the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test:0.96\n",
      "MSE on train:1.16\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy (loss) on test set\n",
    "mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})\n",
    "mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})\n",
    "print('MSE on test:' + str(np.round(mse_test, 2)))\n",
    "print('MSE on train:' + str(np.round(mse_train, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Example\n",
    "\n",
    "For the classification example, we generate data as follows:\n",
    "\n",
    "The input data will be a sample of size 50 from a Normal(mean = -1, sd = 1) and a sample of 50 from a Normal(mean = 1, sd = 1).\n",
    "\n",
    "The target data will be 50 values of 0 and 50 values of 1.\n",
    "\n",
    "We fit the binary classification model:\n",
    "\n",
    "- If $sigmoid(x+A)<0.5$ Then we predict class 0\n",
    "- If $sigmoid(x+A)>=0.5$ Then we predict class 1\n",
    "\n",
    "Theoretically A should be\n",
    "\n",
    "$$ - \\frac{mean1 + mean2}{2} = 0$$\n",
    "\n",
    "We start by resetting the computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ops' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e67971e9b9a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ops' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Classification Data and Targets\n",
    "\n",
    "We generate the classification data as described above.  Then we create the necessary placeholders.\n",
    "\n",
    "After, we split the data in a 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(2, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the model variable, `A`, and the model operation, which is the adding of `A` to the input data.  Note that we do not put the `sigmoid()` function in here because it will be included in the loss function.  This also means that for prediction, we will need to include the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))\n",
    "\n",
    "# Add operation to graph\n",
    "# Want to create the operstion sigmoid(x + A)\n",
    "# Note, the sigmoid() part is in the loss function\n",
    "my_output = tf.add(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimization Function, and Variable Initialization\n",
    "\n",
    "The loss will be the sigmoid-cross-entropy.  We wrap that function in a `tf.reduce_mean()` so that we can reduce the sigmoid-cross-entropy over the whole batch.\n",
    "\n",
    "The optimization function we use is again the standard Gradient Descent Optimization with a learning rate of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add classification loss (cross entropy)\n",
    "xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target))\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Classification\n",
    "\n",
    "We iterate the classification training operation for 1800 iterations and print off the `A` values along with the loss every 200 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #2000 A = [-0.49595693]\nLoss = 0.326879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #4000 A = [-0.52539617]\nLoss = 0.258017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #6000 A = [-0.47863284]\nLoss = 0.303386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #8000 A = [-0.51497865]\nLoss = 0.301927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #10000 A = [-0.51471639]\nLoss = 0.165261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #12000 A = [-0.53905213]\nLoss = 0.220324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #14000 A = [-0.48589557]\nLoss = 0.21062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #16000 A = [-0.49749666]\nLoss = 0.257553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #18000 A = [-0.51881528]\nLoss = 0.314755\n"
     ]
    }
   ],
   "source": [
    "# Run loop\n",
    "for i in range(18000):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = [x_vals_train[rand_index]]\n",
    "    rand_y = [y_vals_train[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%2000==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51881528], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.925\nAccuracy on test set: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuEVEYkaJW0QkZpS4RURiRolbRCRm/j/wH43twjPT/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07848ac358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Predictions on test set\n",
    "y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))\n",
    "correct_prediction = tf.equal(y_prediction, y_target)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "acc_value_test = sess.run(accuracy, feed_dict={x_data: [x_vals_test], y_target: [y_vals_test]})\n",
    "acc_value_train = sess.run(accuracy, feed_dict={x_data: [x_vals_train], y_target: [y_vals_train]})\n",
    "print('Accuracy on train set: ' + str(acc_value_train))\n",
    "print('Accuracy on test set: ' + str(acc_value_test))\n",
    "\n",
    "# Plot classification result\n",
    "A_result = -sess.run(A)\n",
    "bins = np.linspace(-5, 5, 50)\n",
    "plt.hist(x_vals[0:50], bins, alpha=0.5, label='N(-1,1)', color='white')\n",
    "plt.hist(x_vals[50:100], bins[0:50], alpha=0.5, label='N(2,1)', color='red')\n",
    "plt.plot((A_result, A_result), (0, 8), 'k--', linewidth=3, label='A = '+ str(np.round(A_result, 2)))\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Binary Classifier, Accuracy=' + str(np.round(acc_value_test, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
