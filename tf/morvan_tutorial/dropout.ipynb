{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs,in_size,out_size,n_layer,activation_function=None):\n",
    "    layer_name = \"layer%s\" % n_layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size,out_size],name='w'))\n",
    "            tf.summary.histogram(layer_name+\"/weights\",Weights)\n",
    "        with tf.name_scope('bias'):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size])+0.1,name='b')\n",
    "            tf.summary.histogram(layer_name+\"/bias\",biases)\n",
    "        Wx_plus_b = tf.matmul(inputs,Weights) + biases\n",
    "        Wx_plus_b = tf.nn.dropout(Wx_plus_b,keep_prob)\n",
    "        if(activation_function is None):\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])  # 8x8\n",
    "ys = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output layer\n",
    "l1 = add_layer(xs, 64, 50, 1, activation_function=tf.nn.tanh)\n",
    "l2 = add_layer(l1, 50, 50, 1, activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l2, 50, 10, 2, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1]))  # loss\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(\"logs/train\",sess.graph)\n",
    "test_writer = tf.summary.FileWriter(\"logs/test\",sess.graph)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs,v_ys,prob):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs,keep_prob:prob})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs: v_xs, ys: v_ys,keep_prob:prob})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107407\n",
      "0.353704\n",
      "0.448148\n",
      "0.544444\n",
      "0.609259\n",
      "0.607407\n",
      "0.675926\n",
      "0.707407\n",
      "0.711111\n",
      "0.722222\n",
      "0.751852\n",
      "0.744444\n",
      "0.768519\n",
      "0.792593\n",
      "0.781482\n",
      "0.77963\n",
      "0.77963\n",
      "0.814815\n",
      "0.790741\n",
      "0.8\n",
      "0.805556\n",
      "0.792593\n",
      "0.812963\n",
      "0.824074\n",
      "0.805556\n",
      "0.82037\n",
      "0.82963\n",
      "0.835185\n",
      "0.82037\n",
      "0.844444\n",
      "0.837037\n",
      "0.827778\n",
      "0.840741\n",
      "0.833333\n",
      "0.851852\n",
      "0.837037\n",
      "0.851852\n",
      "0.848148\n",
      "0.857407\n",
      "0.85\n",
      "0.861111\n",
      "0.862963\n",
      "0.87037\n",
      "0.874074\n",
      "0.87037\n",
      "0.861111\n",
      "0.851852\n",
      "0.881481\n",
      "0.862963\n",
      "0.864815\n",
      "0.87963\n",
      "0.87037\n",
      "0.881481\n",
      "0.885185\n",
      "0.883333\n",
      "0.887037\n",
      "0.883333\n",
      "0.887037\n",
      "0.9\n",
      "0.896296\n",
      "0.885185\n",
      "0.892593\n",
      "0.905556\n",
      "0.887037\n",
      "0.901852\n",
      "0.892593\n",
      "0.901852\n",
      "0.896296\n",
      "0.894444\n",
      "0.9\n",
      "0.894444\n",
      "0.890741\n",
      "0.9\n",
      "0.898148\n",
      "0.901852\n",
      "0.907407\n",
      "0.896296\n",
      "0.901852\n",
      "0.901852\n",
      "0.9\n",
      "0.903704\n",
      "0.901852\n",
      "0.907407\n",
      "0.901852\n",
      "0.911111\n",
      "0.905556\n",
      "0.905556\n",
      "0.909259\n",
      "0.911111\n",
      "0.905556\n",
      "0.907407\n",
      "0.905556\n",
      "0.907407\n",
      "0.907407\n",
      "0.901852\n",
      "0.907407\n",
      "0.912963\n",
      "0.907407\n",
      "0.907407\n",
      "0.909259\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "for i in range(2000):\n",
    "    sess.run(train_step,feed_dict={xs:X_train,ys:y_train,keep_prob:0.6})\n",
    "    if(i%20==0):\n",
    "#         train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n",
    "#         test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n",
    "#         train_writer.add_summary(train_result, i)\n",
    "#         test_writer.add_summary(test_result, i)\n",
    "        res = compute_accuracy(X_test,y_test,1)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
